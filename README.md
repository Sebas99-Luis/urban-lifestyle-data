# üè¢ Urban Lifestyle AB: Modern Data Stack Project

Este proyecto representa una soluci√≥n integral de **Ingenier√≠a de Datos (End-to-End)** dise√±ada para automatizar el an√°lisis financiero y operativo de la empresa Urban Lifestyle AB. El objetivo principal es transformar datos crudos de Ventas, Inventario y Recursos Humanos en un **Dashboard de Rentabilidad Operativa (P&L)** din√°mico.

---

## üöÄ 1. Arquitectura del Proyecto

El proyecto utiliza un enfoque **ELT (Extract, Load, Transform)** moderno, integrando herramientas l√≠deres en la industria para garantizar escalabilidad, calidad y automatizaci√≥n.



### üõ†Ô∏è Tech Stack
* **Data Warehouse:** [Google BigQuery](https://cloud.google.com/bigquery) (Cloud Storage & Compute).
* **Transformaci√≥n de Datos:** [dbt (data build tool)](https://www.getdbt.com/) - L√≥gica de negocio y calidad.
* **Orquestaci√≥n:** [Apache Airflow](https://airflow.apache.org/) (v√≠a Astro CLI) - Automatizaci√≥n de procesos.
* **Contenedores:** [Docker](https://www.docker.com/) - Entorno de desarrollo aislado.
* **Visualizaci√≥n:** [Google Looker Studio](https://lookerstudio.google.com/) - BI & Reporting.

---

## üìä 2. Flujo de Datos (Data Pipeline)

El pipeline de datos est√° dise√±ado en capas para asegurar la integridad de la informaci√≥n:

1.  **Capa Bronze (Raw):** Ingesta de datos crudos en formato CSV/JSON a BigQuery.
2.  **Capa Silver (Staging):** Limpieza, normalizaci√≥n de tipos de datos y renombrado de columnas mediante dbt.
3.  **Capa Gold (Marts):** Aplicaci√≥n de l√≥gica de negocio compleja para el c√°lculo de m√°rgenes, costos de n√≥mina y beneficio neto final (`fct_business_profit`).



---

## ‚öôÔ∏è 3. Instalaci√≥n y Configuraci√≥n

Siga estos pasos para replicar el entorno de desarrollo local:

### Requisitos Previos
* Docker Desktop.
* Astro CLI.
* Cuenta en Google Cloud Platform (GCP).

### Paso a Paso
1. **Clonar el repositorio:**
   ```bash
   git clone [https://github.com/tu-usuario/urban-lifestyle-data.git](https://github.com/tu-usuario/urban-lifestyle-data.git)
   cd urban-airflow

   Configurar Credenciales:

Coloque su archivo gcp_key.json (Service Account de GCP) en la carpeta dags/.

El proyecto est√° configurado para leer las credenciales desde la ruta interna de Docker: /usr/local/airflow/dags/gcp_key.json.

Levantar el Orquestador:

PowerShell
astro dev start
Acceder a las interfaces:

Airflow: http://localhost:8080 (User: admin / Pass: admin)

BigQuery: Consola de GCP.

## üìà 4. Visualizaci√≥n y Business Intelligence
El resultado final es un Dashboard interactivo que permite a la gerencia monitorear:

KPIs Globales: Ingresos Totales, Margen Bruto y Beneficio Neto.

An√°lisis por Tienda: Comparativa de rentabilidad real (Ventas vs Costos Operativos).

Tendencias: Evoluci√≥n temporal de ingresos frente a gastos de personal.

## üîí 5. Seguridad y Calidad
Tests de dbt: Se ejecutan validaciones autom√°ticas de unicidad, valores no nulos y relaciones de integridad referencial.

Seguridad: El archivo de credenciales gcp_key.json est√° excluido del control de versiones mediante .gitignore.

Desarrollado por: [Tu Nombre/Empresa] Estado del Proyecto: ‚úÖ Desplegado y Operativo


---

### üí° Pr√≥ximo Paso:
Este es el **Punto 1** del checklist. ¬øTe gustar√≠a que preparemos ahora el **Punto 2: El Diccionario de Datos y Lineage de dbt**? (Este es fundamental para que el cliente entienda exactamente de d√≥nde sale cada n√∫mero del P&L).
